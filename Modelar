


#### To do list:
# 1 # GRID 10 x 10 km: Vetor > Investigar > grade vetorial : x=0.1000
# 2 # Cruzamento espacial da camada alvo (pontos de coleta/grid de entrevistas) com as camadas dos dados ambientais
# - Vetor > Gerenciar dados> Unir atributos por localização
# - podes transferir os dados brutos, utilizando a opção “Tomar atributos da primeira feição localizada”, 
# - ou transferir os dados sumarizados, média, soma, mínima, máxima ou mediana, utilizando a função “Tomar sumário de feições intersectantes”
# 3 # Modelagem Hierarquica de occupação
# 4 # Criar arquivos .tif ou .asc dos atributos ambientais do estado: declividade, densidade de humanos...
# - Polígonos em raster : complemento GDALtools "Raster > Conversion > Rasterizar (lembrar de salvar SRC)
# - Raster> extração > cortador: camada mascara=polígono base(alagoas)
# - Declividade: Raster > análise de terreno >“Camada com as elevações” =altitude; Fatorz=1
# 5 # Mapa


#########################################################################
# Polígono da ocorrência: 						#
# 1- Pontos presença em mapa de calor					#
# 2- Raster> extração > cortador: camada mascara=polígono base(alagoas)	#
# 3- Raster > calculadora raster : camada>0.9				#
# 4- Raster > Conversor >Poligonizar 					#
#########################################################################


########## MODELAGEM HIERARQUICA CPB ->OccuFP->Occu

data <- read.table(file = "clipboard", sep = "\t", header=TRUE)
str(data)
y <- as.matrix(data[,1:5]) # Grab 2006-9 monkeys det/nondet data
solos <- data[,"Solos_cor"]
chu <- data[,"chu"]
tmax <- data[,"Temp_max"]
tmin <- data[,"Temp_min"]
tmed <- data[,"Temp_med"]

# Correlacionar covariates
covs <- cbind(solos, chu, tmax, tmin, tmed)
par(mfrow = c(3,3))
for(i in 1:8){
hist(covs[,i], breaks = 50, col = "grey", main = colnames(covs)[i])
}
pairs(cbind(solos, chu, tmax, tmin, tmed))


# Load unmarked, format data (Occu=classique or OccuFP=false-positive) and summarize
library(unmarked)
umf1 <- unmarkedFrameOccuFP(y = y, siteCovs = data.frame(solos = solos, chu = chu, 
tmax = tmax, tmin = tmin, tmed = tmed), type = 3 )
#type 1: assume-se que o processo de detecção é idêntico aos modelos clássicos, onde as probabilidades de falsos negativos são estimadas, mas os falsos positivos não ocorrem. 
#type 2: podemos ter falsos negativos e falsos positivos. Tanto p (a real probabilidade de detecção) e fp (a - a probabilidade de observar falsos positivos) são estimados para as ocasiões em que este tipo de dados podem ocorrer. 
#type 3: assumimos que as observações podem incluir detecções confirmadas(=2) (assume-se que falsos positivos não ocorrem) e detecções incertas que podem ou não incluir falsos positivos. 
summary(umf1)

m1 <- occuFP(detformula = ~ 1, FPformula = ~1, stateformula = ~ 1, data = umf1) #modelo nulo
#Error in if (sum(type[2:3]) == 0) stop("Only type 1 data. No data types with false positives. Use occu instead.") 

umf <- unmarkedFrameOccu(y = y, siteCovs = data.frame(solos = solos, chu = chu, 
tmax = tmax, tmin = tmin, tmed = tmed))


# Fit a series of models for detection first and do model selection
summary(fm1 <- occu(~1 ~1, data=umf))
summary(fm2 <- occu(~1 ~tmin , data=umf))
summary(fm3 <- occu(~1 ~tmax, data=umf))
cbind(fm1@AIC, fm2@AIC, fm3@AIC)       # outra maneira de selecionar pelo AIC



########## MODELAGEM HIERARQUICA ENTREVISTAS >OccuFP->Occu

data <- read.table(file = "clipboard", sep = "\t", header=TRUE)
str(data)
data[-c(1,10,18,19,26,37,55,74,92),]

dataa = subset(data, data$biom == 1)
datam = subset(data, data$biom == 2)
str(datam)
str(dataa)

#possivel colocar variavel categorica (ex: estratos) mas ela deve ser numerica
#se usar letra o R dá erro e fecha

#lon.orig <- data[,"Lon"] # Unstandardised, original values of covariates
#lat.orig <- data[,"Lat"]
#alt.orig <- data[,"Alt"]
dec.orig <- data[,"Dec"]
veg.orig <- data[,"veg"]
agua <- data[,"agua"]
#agdis.orig <- data[,"agdis"]
area.orig <- data[,"areaKm2"]
par.orig <- data[,"par"]
form.orig <- data[,"form"]
isol.orig <- data[,"isol"]
urbd.orig <- data[,"urbd"]
agrd.orig <- data[,"agrd"]
pecd.orig <- data[,"pecd"]
popq.orig <- data[,"popq"]

#lon.orig <- datam[,"Lon"] # Unstandardised, original values of covariates
#lat.orig <- datam[,"Lat"]
#alt.orig <- datam[,"Alt"]
dec.orig <- datam[,"Dec"]
veg.orig <- datam[,"veg"]
area.orig <- datam[,"areaKm2"]
par.orig <- datam[,"par"]
form.orig <- datam[,"form"]
isol.orig <- datam[,"isol"]
urbd.orig <- datam[,"urbd"]
agrd.orig <- datam[,"monod"]
pecd.orig <- datam[,"pastd"]
popq.orig <- datam[,"popq"]

quest <- read.table(file = "clipboard", sep = "\t", header=TRUE)
questm = quest[-c(1:54,89),] 
edit(questm)

prego <- as.matrix(questm[,15:18]) # Monkeys det/nondet data

queca.orig <- as.matrix(questm[,7:10])
queco.orig <- as.matrix(questm[,11:14])

# Standardise covariates and mean-impute date and duration
# Compute means and standard deviations
means <- c(apply(cbind(dec.orig, veg.orig, area.orig, par.orig, form.orig,  
isol.orig, urbd.orig, agrd.orig, pecd.orig, popq.orig), 2, mean, na.rm=T)) 
sds <- c(apply(cbind(dec.orig, veg.orig, area.orig, par.orig, form.orig,  
isol.orig, urbd.orig, agrd.orig, pecd.orig, popq.orig), 2, sd, na.rm=T))
#na.rm=T esse codigo permite q a presença de NA não estrague o calculo 

sds <- c(apply(cbind(lon.orig, lat.orig, alt.orig, dec.orig, veg.orig, agdis.orig, area.orig, par.orig, form.orig,  
isol.orig, urbd.orig, agrd.orig, pecd.orig, popq.orig), 2, sd))

# Scale covariates  => ATENCAO: ordem das medias= ordem usada na funcao acima
#lon <- (lon.orig - means[1]) / sds[1]
#lat <- (lat.orig - means[2]) / sds[2]
#alt <- (alt.orig - means[3]) / sds[3]
dec <- (dec.orig - means[1]) / sds[1] #conferir para ter certeza de usar os valores certos
veg <- (veg.orig - means[2]) / sds[2]
#agdis <- (agdis.orig - means[3]) / sds[3]
area <- (area.orig - means[3]) / sds[3]
par <- (par.orig - means[4]) / sds[4]
form <- (form.orig - means[5]) / sds[5]
isol <- (isol.orig - means[6]) / sds[6]
urbd <- (urbd.orig - means[7]) / sds[7]
agrd <- (agrd.orig - means[8]) / sds[8]
pecd <- (pecd.orig - means[9]) / sds[9]
popq <- (popq.orig - means[10]) / sds[10]


#### OU  >>>>>> primeiro padroniza e depois chama um a um = NAO FUNCIONA NO UNMARKED
#pais <-decostand(paisagem, method="standardize") 	#Dados padronizados
#lon.s <- pais[,"Lon"]
#lat.s <- pais[,"Lat"]
#alt.s <- pais[,"Alt"]
dec.s <- pais[,"Dec"]
veg.s <- pais[,"veg"]
agua.s <- pais[,"agua"]
#agdis.s <- pais[,"agdis"]
area.s <- pais[,"area"]
par.s <- pais[,"par"]
form.s <- pais[,"form"]
isol.s <- pais[,"isol"]
urbd.s <- pais[,"urbd"]
agrd.s <- pais[,"agrd"]
pecd.s <- pais[,"pecd"]
popq.s <- pais[,"popq"]

# Load unmarked, format data and summarize
library(unmarked)
umf <- unmarkedFrameOccu(y = prego, siteCovs = data.frame(dec = dec, veg = veg,
par = par, form = form, isol = isol, urbd = urbd, 
agrd = agrd, pecd = pecd, popq = popq), 
obsCovs = list(queca = queca.orig, queco = queco.orig))
summary(umf)

# Fit a series of models for detection first and do model selection
summary(fm1 <- occu(~1 ~1, data=umf))
summary(fm2 <- occu(~queca ~1, data=umf))
summary(fm3 <- occu(~queco ~1, data=umf))
summary(fm4 <- occu(~queca+queco ~1, data=umf)) #menorAIC 42.48622

# Selecionar pelo AIC
cbind(fm1@AIC, fm2@AIC, fm3@AIC, fm4@AIC)       

### Continue with model fitting for occupancy, guided by AIC as we go

#Check effects of spatial location
summary(fm7 <- occu(~queca ~lon, data=umf))
summary(fm8 <- occu(~queca ~lat, data=umf))
summary(fm9 <- occu(~queca ~lon+lat, data=umf))
cbind(fm2@AIC, fm7@AIC, fm8@AIC, fm9@AIC)

#Check effects of water
summary(fm12 <- occu(~queca ~agua, data=umf))
summary(fm13 <- occu(~queca ~agdis, data=umf))
summary(fm14 <- occu(~queca ~agua+agdis, data=umf))
cbind(fm2@AIC, fm12@AIC, fm13@AIC, fm14@AIC)

#Check effects of declivity and vegetation cover 
summary(fm17 <- occu(~queca+queco ~dec, data=umf))
summary(fm18 <- occu(~queca+queco ~veg, data=umf))
summary(fm19 <- occu(~queca+queco ~dec+veg, data=umf))
cbind(fm4@AIC, fm17@AIC, fm18@AIC, fm19@AIC)

#Check effects of size, format and isolation
summary(fm22 <- occu(~queca+queco ~area, data=umf))
summary(fm23 <- occu(~queca+queco ~par, data=umf)) #menorAIC 38.23625
summary(fm24 <- occu(~queca+queco ~form, data=umf))
summary(fm25 <- occu(~queca+queco ~isol, data=umf)) #unico model converge
summary(fm26 <- occu(~queca+queco ~area+par, data=umf))#40.23049
summary(fm27 <- occu(~queca+queco ~area+form, data=umf))
summary(fm28 <- occu(~queca+queco ~area+isol, data=umf))
summary(fm29 <- occu(~queca+queco ~par+isol, data=umf))#39.98014
summary(fm30 <- occu(~queca+queco ~area+par+isol, data=umf))#41.9269
summary(fm31 <- occu(~queca+queco ~area+form+isol, data=umf))
cbind(fm4@AIC, fm22@AIC, fm23@AIC, fm24@AIC, fm25@AIC, fm26@AIC, fm27@AIC, fm28@AIC,
fm29@AIC, fm30@AIC, fm31@AIC)

# Check effects of Anthropic Matriz
summary(fm32 <- occu(~queca+queco ~urbd, data=umf))#
summary(fm33 <- occu(~queca+queco ~agrd, data=umf))
summary(fm34 <- occu(~queca+queco ~pecd, data=umf))
summary(fm35 <- occu(~queca+queco ~popq, data=umf))
summary(fm36 <- occu(~queca+queco ~popq+urbd, data=umf))
summary(fm37 <- occu(~queca+queco ~popq+agrd, data=umf))
summary(fm38 <- occu(~queca+queco ~popq+pecd, data=umf))
summary(fm39 <- occu(~queca+queco ~popq+agrd+pecd, data=umf))
summary(fm40 <- occu(~queca+queco ~urbd+agrd, data=umf))
summary(fm41 <- occu(~queca+queco ~urbd+pecd, data=umf))
summary(fm42 <- occu(~queca+queco ~agrd+pecd, data=umf))
summary(fm43 <- occu(~queca+queco ~popq+urbd+agrd+pecd, data=umf))
cbind(fm4@AIC, fm32@AIC, fm33@AIC, fm34@AIC, fm35@AIC, fm36@AIC, 
fm37@AIC, fm38@AIC, fm39@AIC, fm40@AIC, fm41@AIC, fm42@AIC, fm43@AIC)

#Check best models (mantém os melhor das etapas anterior e testa +combinações)

summary(fm50 <- occu(~queca+queco ~par+urbd, data=umf))#38.67757
cbind(fm4@AIC, fm23@AIC ,fm50@AIC)


#################### PLOTAR gráficos de predições UNI-dimensionais   (occu x cov)

# Create new covariates for prediction ('prediction covs')
orig.elev <- seq(200, 2500,,100) # New covs for prediction
orig.forest <- seq(0, 100,,100)
orig.date <- seq(15, 110,,100)
orig.duration <- seq(100, 550,,100)
ep <- (orig.elev - means[1]) / sds[1] # Standardize them like actual covs
fp <- (orig.forest - means[2]) / sds[2]
dp <- (orig.date - means[3]) / sds[3]
durp <- (orig.duration - means[4]) / sds[4]

# Obtain predictions
newData <- data.frame(elev=ep, forest=0)
pred.occ.elev <- predict(fm20, type="state", newdata=newData, appendData=TRUE)
newData <- data.frame(elev=0, forest=fp)
pred.occ.forest <- predict(fm20, type="state", newdata=newData, appendData=TRUE)
newData <- data.frame(date=dp, dur=0)
pred.det.date <- predict(fm20, type="det", newdata=newData, appendData=TRUE)
newData <- data.frame(date=0, dur=durp)
pred.det.dur <- predict(fm20, type="det", newdata=newData, appendData=TRUE)

# Plot predictions against unstandardized 'prediction covs'
par(mfrow = c(2,2), mar = c(5,5,2,3), cex.lab = 1.2)
plot(pred.occ.elev[[1]] ~ orig.elev, type = "l", lwd = 3, col = "blue", ylim = c(0,1),
las = 1, ylab = "Pred. occupancy prob.", xlab = "Elevation (m)", frame = F)
matlines(orig.elev, pred.occ.elev[,3:4], lty = 1, lwd = 1, col = "grey")
plot(pred.occ.forest[[1]] ~ orig.forest, type = "l", lwd = 3, col = "blue", ylim = c(0,1),
las = 1, ylab = "Pred. occupancy prob.", xlab = "Forest cover (%)", frame = F)
matlines(orig.forest, pred.occ.forest[,3:4], lty = 1, lwd = 1, col = "grey")
plot(pred.det.date[[1]] ~ orig.date, type = "l", lwd = 3, col = "blue", ylim = c(0,1),
las = 1, ylab = "Pred. detection prob.", xlab = "Date (1 = 1 April)", frame = F)
matlines(orig.date, pred.det.date[,3:4], lty = 1, lwd = 1, col = "grey")
plot(pred.det.dur[[1]] ~ orig.duration, type = "l", lwd = 3, col = "blue", ylim = c(0,1), las
= 1, ylab = "Pred. detection prob.", xlab = "Survey duration (min)", frame = F)
matlines(orig.duration, pred.det.dur[,3:4], lty = 1, lwd = 1, col = "grey")


#################### PLOTAR gráficos de predições BI-dimensionais   (cov x cov x occu)

# Predict abundance and detection jointly along two separate covariate gradients
# abundance ~ (forest, elevation) and detection ~ (survey duration, date)
pred.matrix1 <- pred.matrix2 <- array(NA, dim = c(100, 100)) # Define arrays
for(i in 1:100){
for(j in 1:100){
newData1 <- data.frame(elev=ep[i], forest=fp[j]) # For abundance
pred <- predict(fm20, type="state", newdata=newData1)
pred.matrix1[i, j] <- pred$Predicted
newData2 <- data.frame(dur=durp[i], date=dp[j]) # For detection
pred <- predict(fm20, type="det", newdata=newData2)
pred.matrix2[i, j] <- pred$Predicted
}
}
par(mfrow = c(1,2), cex.lab = 1.2)
mapPalette <- colorRampPalette(c("grey", "yellow", "orange", "red"))
image(x=orig.elev, y=orig.forest, z=pred.matrix1, col = mapPalette(100), axes = FALSE,
xlab = "Elevation [m]", ylab = "Forest cover [%]")
contour(x=orig.elev, y=orig.forest, z=pred.matrix1, add = TRUE, lwd = 1.5, col = "blue",
labcex = 1.3)
axis(1, at = seq(min(orig.elev), max(orig.elev), by = 250))
axis(2, at = seq(0, 100, by = 10))
box()
title(main = "Expected squirrel occurrence prob.", font.main = 1)
points(data$ele, data$forest, pch="+", cex=1)
image(x=orig.duration, y=orig.date, z=pred.matrix2, col = mapPalette(100), axes = FALSE,
xlab = "Survey duration [min]", ylab = "Date (1 = April 1)")
contour(x=orig.duration, y=orig.date, z=pred.matrix2, add = TRUE, lwd = 1.5, col = "blue",
labcex = 1.3)
axis(1, at = seq(min(orig.duration), max(orig.duration), by = 50))
axis(2, at = seq(0, 100, by = 10))
box()
title(main = "Expected squirrel detection prob.", font.main = 1)
matpoints(as.matrix(data[, 13:15]), as.matrix(data[, 10:12]), pch="+", cex=1)


############# CRIAR MAPAS DE DISTRIBUIÇÂO

####### Load the landscape data

library(raster)
library(rgdal)

setwd("")         # diretorio da pasta com os arquivos .tif 

bio1.tif <- raster("bio01_neotropic_50km_gcs_wgs84.tif")        # importar um arquivo .tif ou .asc no formato rasterlayer 
bio1.tif              # visualizar as propriedades do arquivo raster importado 
plot(bio1.tif)        # plot do raster 

# Podemos importar diversos arquivos separadamente, atribuindo cada um a uma variável 
#ou podemos utilizar a função 'stack'

list.files(pattern = ".tif")           # listar os nomes dos arquivos na pasta do diretorio 
tif <- list.files(pattern = ".tif") 
tif.bios <- stack(tif)                 # importar os arquivos .tif no formato rasterstack 
tif.bios
names(tif.bios) <- paste0("bio", 1:19)  # renomear os arquivos raster importados 
tif.bios 
plot(tif.bios)            # plot de todos dos raster 
plot(tif.bios[[c(2, 5, 17, 18)]], col = rainbow(100, .7))     # plot de alguns dos raster 


# Get predictions of occupancy prob for each 1km2 quadrat
newData <- data.frame(elev = (tif.bios$elevation - means[1])/sds[1], forest = (tif.bios$forest - means[2])/sds[2])
predpsi <- predict(fm20, type="state", newdata=newData)        #fm20 = melhor função occu do unMarked


# Define new data frame with coordinates and outcome to be plotted
PARAM <- data.frame(x = tif.bios$x, y = tif.bios$y, z = predpsi$Predicted)
r1 <- rasterFromXYZ(PARAM)     # convert into raster object

# Mask quadrats with elevation greater than 2250
elev <- rasterFromXYZ(cbind(tif.bios$x, tif.bios$y, tif.bios$elevation))
elev[elev > 2250] <- NA
r1 <- mask(r1, elev)

# Plot species distribution map (Fig. 10-14 left)
par(mfrow = c(1,2), mar = c(1,2,2,5))
mapPalette <- colorRampPalette(c("grey", "yellow", "orange", "red"))
plot(r1, col = mapPalette(100), axes = F, box = F, main = "Capuchin monkey distribution between 2006 and 2009")

#Plot landscape characteristics
lakes <- readOGR(".", "lakes")
rivers <- readOGR(".", "rivers")
border <- readOGR(".", "border")
plot(rivers, col = "dodgerblue", add = TRUE)
plot(border, col = "transparent", lwd = 1.5, add = TRUE)
plot(lakes, col = "skyblue", border = "royalblue", add = TRUE)

# Plot SE of the species distrbution map (Fig. 10-14 right)
r2 <- rasterFromXYZ(data.frame(x = tif.bios$x, y = tif.bios$y, z = predpsi$SE))
r2 <- mask(r2, elev)
plot(r2, col = mapPalette(100), axes = F, box = F, main = "Uncertainty map between 2006 and 2009")
plot(rivers, col = "dodgerblue", add = TRUE)
plot(border, col = "transparent", lwd = 1.5, add = TRUE)
plot(lakes, col = "skyblue", border = "royalblue", add = TRUE)
points(data$coordx, data$coordy, pch = "+", cex = 0.8)        #add pontos de coleta






###### DENDROGRAMA + HEATMAP
#(1)Chamar os dados e pacote
library(vegan)
library(gplots)
library(RColorBrewer)

setwd("C:/R/intro/")
poli<-read.table("data-dout.txt",header=T,sep="\t")
prob<-poli[,1:4] #probabilidades de ocupação
row.names(prob)<-poli$local #nomeou todas as linhas com essa coluna
prob<-prob[,-1]		#depois tira essa coluna p ficar só o data frame

##
# (2) Criar mapa de calor comparando entre fragmentos:

# usando probabilidades de ocupação entre sp
scaleyellowred<- colorRampPalette(c("lightyellow","red"),space="rgb")(100)
heatmap(as.matrix(prob),Rowv=NA,Colv=NA,col=scaleyellowred) #cria mapa de calor

maxab<-apply(prob,1,max) # 2=colum 1=linha max=funçao q quero aplicar:aqui selecionei os valores maximos de cada linha
maxab
n1<-names(which(maxab<0.4))	#seleciona fragm com menos prob de ocupação
prob.1<-prob[,-which(names(prob) %in% n1)]	#retira esses fragm
heatmap(as.matrix(prob.1),Rowv=NA,Colv=NA,col=scaleyellowred,
margins=c(5,6))		#cria novo mapa de calor só com fragm com maior prob

#(3)Transformação dos dados da paisagem
paisagem<-poli[,5:10]
pairs(paisagem) 	#correlações
row.names(paisagem)<-poli$local #nomeou todas as linhas com essa coluna

# ou log
pairs(log(paisagem)) #confere
lopais<-log(paisagem) 
# ou padronização
pais.pad<-decostand(paisagem, method="standardize") 	#ou Padronização dos dados
#
pais.pad<-scale(paisagem)
##
#(4) Criar matriz de distancia
pais.bray <-vegdist(pais.pad, method="bray") #Bray-curtis
##
#(5) calcular cluster e coeficiente de correlaçao cofenetico 
cluster<-hclust(pais.bray, method="average")
cluster.coph<-cophenetic(cluster)

#compara matriz cofenetica com a matriz euclidiana, mais perto de 1 = +semelhantes :D
cor(pais.bray, cluster.coph) #resultado= 0.8686003 #nao usar a padronização pro metodo bray
##
# (6) Gerar mapa de calor com cluster
heatmap(as.matrix(prob),Rowv=as.dendrogram(cluster),
Colv=NA,col=scaleyellowred, margins=c(5,20),cexCol=1, cexRow=0.5)
	#cex=tamanho da letra; margins= proporção das margens entre colunas e linhas

help(heatmap)



